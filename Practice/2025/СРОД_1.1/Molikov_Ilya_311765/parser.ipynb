{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488DRkiLwskIcZe.json'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "def parse_recipe_steps_advanced(url, base_url):\n",
    "    \"\"\"\n",
    "    Улучшенная версия парсера с обработкой разных вариантов разметки\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Ищем заголовок разными способами\n",
    "        steps_header = soup.find('h2', string='Пошаговый рецепт')\n",
    "        if not steps_header:\n",
    "            steps_header = soup.find('h2', string=re.compile(r'Пошаговый', re.IGNORECASE))\n",
    "        if not steps_header:\n",
    "            steps_header = soup.find('h3', string=re.compile(r'Пошаговый', re.IGNORECASE))\n",
    "        \n",
    "        if not steps_header:\n",
    "            print(\"Не найден заголовок с пошаговым рецептом\")\n",
    "            return None\n",
    "        \n",
    "        recipe_steps = []\n",
    "        current_element = steps_header.find_next_sibling()\n",
    "        \n",
    "        while current_element:\n",
    "            # Проверяем разные варианты заголовков шагов\n",
    "            if (current_element.name in ['h4', 'h3', 'h5'] and \n",
    "                re.match(r'Шаг\\s*\\d+', current_element.get_text(), re.IGNORECASE)):\n",
    "                \n",
    "                step_number = current_element.get_text().strip()\n",
    "                step_data = {\n",
    "                    'step_number': step_number,\n",
    "                    'step_index': len(recipe_steps) + 1,\n",
    "                    'description': '',\n",
    "                    'image_url': None\n",
    "                }\n",
    "                \n",
    "                # Обрабатываем следующие элементы до следующего шага\n",
    "                next_element = current_element.find_next_sibling()\n",
    "                while (next_element and \n",
    "                       not (next_element.name in ['h4', 'h3', 'h5'] and \n",
    "                            re.match(r'Шаг\\s*\\d+', next_element.get_text(), re.IGNORECASE))):\n",
    "                    \n",
    "                    if next_element.name == 'p':\n",
    "                        # Ищем изображение\n",
    "                        img_tag = next_element.find('img')\n",
    "                        if img_tag:\n",
    "                            for attr in ['src', 'data-src', 'data-original']:\n",
    "                                if img_tag.get(attr):\n",
    "                                    step_data['image_url'] = base_url+img_tag[attr]\n",
    "                                    break\n",
    "                        \n",
    "                        # Добавляем текст\n",
    "                        text = next_element.get_text().strip()\n",
    "                        if text and text != step_data['description']:\n",
    "                            if step_data['description']:\n",
    "                                step_data['description'] += ' ' + text\n",
    "                            else:\n",
    "                                step_data['description'] = text\n",
    "                    \n",
    "                    elif next_element.name == 'div' and next_element.find('img'):\n",
    "                        # Обработка div с изображениями\n",
    "                        img_tag = next_element.find('img')\n",
    "                        for attr in ['src', 'data-src', 'data-original']:\n",
    "                            if img_tag.get(attr):\n",
    "                                step_data['image_url'] = img_tag[attr]\n",
    "                                break\n",
    "                    \n",
    "                    next_element = next_element.find_next_sibling()\n",
    "                    if not next_element:\n",
    "                        break\n",
    "                \n",
    "                recipe_steps.append(step_data)\n",
    "                current_element = next_element\n",
    "            else:\n",
    "                current_element = current_element.find_next_sibling()\n",
    "        \n",
    "        return recipe_steps\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "def parse_ingredients_advanced(soup):\n",
    "    \"\"\"\n",
    "    Парсит ингредиенты с различными стратегиями очистки\n",
    "    \"\"\"\n",
    "    ingredients = []\n",
    "    \n",
    "    ingredients_header = soup.find(['h2', 'h3', 'h4'], \n",
    "                                 string=re.compile(r'Ингредиенты|Продукты|Состав', re.IGNORECASE))\n",
    "    \n",
    "    if ingredients_header:\n",
    "        # Ищем в разных возможных местах\n",
    "        containers = [\n",
    "            ingredients_header.find_next('ul'),\n",
    "            ingredients_header.find_next('ol'),\n",
    "            ingredients_header.find_next('div', class_=re.compile(r'ingredient|product', re.IGNORECASE))\n",
    "        ]\n",
    "        \n",
    "        for container in containers:\n",
    "            if container:\n",
    "                if container.name in ['ul', 'ol']:\n",
    "                    for li in container.find_all('li'):\n",
    "                        ingredient_data = parse_ingredient_item(li.get_text())\n",
    "                        if(not ingredient_data.get(\"name\")):\n",
    "                            continue\n",
    "                        ingredients.append(ingredient_data)\n",
    "                break\n",
    "    \n",
    "    return ingredients\n",
    "\n",
    "def parse_ingredient_item(raw_text):\n",
    "    \"\"\"\n",
    "    Парсит отдельный элемент ингредиента, возвращает структурированные да\n",
    "    нные\n",
    "    \"\"\"\n",
    "    # Очищаем от лишних пробелов\n",
    "    text = ' '.join(raw_text.strip().split())\n",
    "    splitteed=raw_text.split()\n",
    "    # Разделяем на название и количество\n",
    "    parts = re.split(r'[\\n\\t]| {2,}', raw_text)\n",
    "    name=\"\"\n",
    "    for part in parts:\n",
    "        if part:\n",
    "            name = part.strip()\n",
    "            break\n",
    "    if not parts: name = text.strip()\n",
    "    # Пытаемся найти количество (если есть во второй части)\n",
    "    amount = None\n",
    "    unit = None\n",
    "    \n",
    "    if len(parts) > 1:\n",
    "        # Ищем цифры и единицы измерения в оставшихся частях\n",
    "        quantity_text = ' '.join(parts[1:])\n",
    "        quantity_match = re.search(r'(\\d+[\\.,]?\\d*)\\s*([а-яa-z\\.]+)?', quantity_text)\n",
    "        if quantity_match:\n",
    "            amount = quantity_match.group(1)\n",
    "            unit = quantity_match.group(2)\n",
    "    \n",
    "    return {\n",
    "        'name': name\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urljoin\n",
    "def find_video_links_advanced(soup, base_url):\n",
    "    \"\"\"\n",
    "    Расширенный поиск видео ссылок в различных местах\n",
    "    \"\"\"\n",
    "    video_links = {\n",
    "        'mp4': [],\n",
    "        'youtube': [],\n",
    "        'other': []\n",
    "    }\n",
    "    \n",
    "    # Функция для добавления полного URL\n",
    "    def add_full_url(url, type_key):\n",
    "        if url and url not in video_links[type_key]:\n",
    "            full_url = urljoin(base_url, url)\n",
    "            video_links[type_key].append(full_url)\n",
    "    \n",
    "    # 1. Поиск в мета-тегах (Open Graph, Twitter Cards)\n",
    "    meta_tags = soup.find_all('meta')\n",
    "    for tag in meta_tags:\n",
    "        property_name = tag.get('property', '').lower() or tag.get('name', '').lower()\n",
    "        content = tag.get('content', '')\n",
    "        if content.endswith('.mp4'):\n",
    "                add_full_url(content, 'mp4')\n",
    "        elif 'youtube' in content:\n",
    "                video_links['youtube'].append(content)\n",
    "    \n",
    "    # 2. Поиск в тегах <video> и <source>\n",
    "    video_tags = soup.find_all('video')\n",
    "    for video in video_tags:\n",
    "        # Атрибут src у самого video\n",
    "        src = video.get('src')\n",
    "        if src and src.endswith('.mp4'):\n",
    "            add_full_url(src, 'mp4')\n",
    "        \n",
    "        # Теги source внутри video\n",
    "        sources = video.find_all('source')\n",
    "        for source in sources:\n",
    "            src = source.get('src')\n",
    "            type_attr = source.get('type', '')\n",
    "            if src and (src.endswith('.mp4') or 'mp4' in type_attr):\n",
    "                add_full_url(src, 'mp4')\n",
    "    \n",
    "    # 3. Поиск в тегах <a>\n",
    "    youtube_patterns = [\n",
    "        r'youtube\\.com/watch\\?v=([a-zA-Z0-9_-]+)',\n",
    "        r'youtu\\.be/([a-zA-Z0-9_-]+)',\n",
    "        r'youtube\\.com/embed/([a-zA-Z0-9_-]+)'\n",
    "    ]\n",
    "    \n",
    "    all_links = soup.find_all('a', href=True)\n",
    "    for link in all_links:\n",
    "        href = link['href']\n",
    "        \n",
    "        # MP4 ссылки\n",
    "        if href.endswith('.mp4'):\n",
    "            add_full_url(href, 'mp4')\n",
    "            continue\n",
    "        \n",
    "        # YouTube ссылки\n",
    "        for pattern in youtube_patterns:\n",
    "            match = re.search(pattern, href)\n",
    "            if match:\n",
    "                video_id = match.group(1)\n",
    "                youtube_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "                if youtube_url not in video_links['youtube']:\n",
    "                    video_links['youtube'].append(youtube_url)\n",
    "                break\n",
    "    \n",
    "    # 4. Поиск в iframe\n",
    "    iframes = soup.find_all('iframe', src=True)\n",
    "    for iframe in iframes:\n",
    "        src = iframe['src']\n",
    "        for pattern in youtube_patterns:\n",
    "            match = re.search(pattern, src)\n",
    "            if match:\n",
    "                video_id = match.group(1)\n",
    "                youtube_url = f'https://www.youtube.com/watch?v={video_id}'\n",
    "                if youtube_url not in video_links['youtube']:\n",
    "                    video_links['youtube'].append(youtube_url)\n",
    "                break\n",
    "    \n",
    "    return video_links\n",
    "\n",
    "def get_best_video_link(video_links):\n",
    "    \"\"\"\n",
    "    Выбирает лучшую видео ссылку по приоритету\n",
    "    \"\"\"\n",
    "    # Предпочтение: прямые MP4 ссылки\n",
    "    if video_links['mp4']:\n",
    "        return video_links['mp4'][0]  # Первая найденная MP4 ссылка\n",
    "    \n",
    "    # Затем YouTube\n",
    "    if video_links['youtube']:\n",
    "        return video_links['youtube'][0]  # Первая YouTube ссылка\n",
    "    \n",
    "    # Затем другие видео форматы\n",
    "    if video_links['other']:\n",
    "        return video_links['other'][0]\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "def find_ingredient_id_by_lemma(lemma: str, ingredients_file: str) -> int:\n",
    "    \"\"\"Находит ID ингредиента по лемме\"\"\"\n",
    "    if not os.path.exists(ingredients_file):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(ingredients_file, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                if row.get('lemma', '').lower() == lemma.lower():\n",
    "                    return int(row['id'])\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при поиске ингредиента: {e}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "def find_recipe_id_by_url(url: str, recipes_file: str) -> int:\n",
    "    \"\"\"Находит ID ингредиента по лемме\"\"\"\n",
    "    if not os.path.exists(recipes_file):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(recipes_file, 'r', encoding='utf-8') as f:\n",
    "            reader = csv.DictReader(f, delimiter='\\t')\n",
    "            for row in reader:\n",
    "                if row.get('url', '') == url:\n",
    "                    return int(row['id'])\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при поиске рецепта: {e}\")\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import csv\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class IDManager:\n",
    "    \"\"\"Класс для управления ID между вызовами функций\"\"\"\n",
    "    \n",
    "    def __init__(self, state_file='id_state.json'):\n",
    "        self.state_file = state_file\n",
    "        self.state = self._load_state()\n",
    "    \n",
    "    def _load_state(self):\n",
    "        \"\"\"Загружает состояние ID из файла\"\"\"\n",
    "        if os.path.exists(self.state_file):\n",
    "            try:\n",
    "                with open(self.state_file, 'r', encoding='utf-8') as f:\n",
    "                    return json.load(f)\n",
    "            except:\n",
    "                return {'recipe_id': 0, 'ingredient_id': 0, 'step_id': 0, 'video_id': 0}\n",
    "        return {'recipe_id': 0, 'ingredient_id': 0, 'step_id': 0, 'video_id': 0}\n",
    "    \n",
    "    def _save_state(self):\n",
    "        \"\"\"Сохраняет состояние ID в файл\"\"\"\n",
    "        with open(self.state_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.state, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    def get_next_recipe_id(self):\n",
    "        \"\"\"Возвращает следующий ID рецепта\"\"\"\n",
    "        self.state['recipe_id'] += 1\n",
    "        self._save_state()\n",
    "        return self.state['recipe_id']\n",
    "    \n",
    "    def get_next_ingredient_id(self):\n",
    "        \"\"\"Возвращает следующий ID ингредиента\"\"\"\n",
    "        self.state['ingredient_id'] += 1\n",
    "        self._save_state()\n",
    "        return self.state['ingredient_id']\n",
    "    \n",
    "    def get_next_step_id(self):\n",
    "        \"\"\"Возвращает следующий ID шага\"\"\"\n",
    "        self.state['step_id'] += 1\n",
    "        self._save_state()\n",
    "        return self.state['step_id']\n",
    "    \n",
    "    def get_next_video_id(self):\n",
    "        \"\"\"Возвращает следующий ID видео\"\"\"\n",
    "        self.state['video_id'] += 1\n",
    "        self._save_state()\n",
    "        return self.state['video_id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "%pip install pymorphy3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "import pymorphy3\n",
    "\n",
    "class IngredientManager:\n",
    "    \"\"\"Класс для управления ингредиентами с лемматизацией и проверкой уникальности\"\"\"\n",
    "    \n",
    "    def __init__(self, ingredients_file='ingredients.tsv'):\n",
    "        self.ingredients_file = ingredients_file\n",
    "        self.existing_ingredients = self._load_existing_ingredients()\n",
    "        self.morph = pymorphy3.MorphAnalyzer()\n",
    "    \n",
    "    def _load_existing_ingredients(self) -> set[str]:\n",
    "        \"\"\"Загружает существующие леммы ингредиентов из файла\"\"\"\n",
    "        existing_lemmas = set()\n",
    "        \n",
    "        if os.path.exists(self.ingredients_file):\n",
    "            try:\n",
    "                with open(self.ingredients_file, 'r', encoding='utf-8') as f:\n",
    "                    reader = csv.DictReader(f, delimiter='\\t')\n",
    "                    for row in reader:\n",
    "                        if 'lemma' in row and row['lemma']:\n",
    "                            existing_lemmas.add(row['lemma'])\n",
    "            except Exception as e:\n",
    "                print(f\"Ошибка при чтении файла ингредиентов: {e}\")\n",
    "        \n",
    "        return existing_lemmas\n",
    "    \n",
    "    def get_lemma(self, ingredient_name: str) -> str:\n",
    "        \"\"\"\n",
    "        Извлекает лемму главного слова из названия ингредиента\n",
    "        \"\"\"\n",
    "        words = ingredient_name.split()\n",
    "        if not words:\n",
    "            return ingredient_name.lower()\n",
    "        \n",
    "        # Ищем главное слово (обычно последнее или существительное)\n",
    "        main_word = words[-1]  # По умолчанию берем последнее слово\n",
    "        \n",
    "        # Пытаемся найти существительное\n",
    "        for word in words:\n",
    "            parsed = self.morph.parse(word)[0]\n",
    "            if 'NOUN' in parsed.tag:\n",
    "                main_word = word\n",
    "                break\n",
    "        \n",
    "        # Лемматизируем главное слово\n",
    "        parsed = self.morph.parse(main_word)[0]\n",
    "        return parsed.normal_form.lower()\n",
    "    \n",
    "    def is_ingredient_unique(self, lemma: str) -> bool:\n",
    "        \"\"\"Проверяет, есть ли уже такой ингредиент\"\"\"\n",
    "        return lemma not in self.existing_ingredients\n",
    "    \n",
    "    def add_ingredient_lemma(self, lemma: str):\n",
    "        \"\"\"Добавляет лемму в множество существующих\"\"\"\n",
    "        self.existing_ingredients.add(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "def json_to_tsv(original_data: Dict[str, Any], output_dir: str = ''):\n",
    "    \"\"\"\n",
    "    Преобразует JSON данные в три TSV файла с проверкой уникальности ингредиентов\n",
    "    \"\"\"\n",
    "    if (os.path.exists(f'{output_dir}recipes_raw.tsv') and find_recipe_id_by_url(original_data['url'], f'{output_dir}recipes_raw.tsv') is not None) or (os.path.exists(f'{output_dir}recipes.tsv') and find_recipe_id_by_url(original_data['url'], f'{output_dir}recipes.tsv') is not None):\n",
    "        return\n",
    "    # Инициализируем менеджеры\n",
    "    id_manager = IDManager()\n",
    "    ingredient_manager = IngredientManager(f'{output_dir}ingredients.tsv')\n",
    "    \n",
    "    # Получаем уникальные ID\n",
    "    recipe_id = id_manager.get_next_recipe_id()\n",
    "    \n",
    "    # 1. Обрабатываем ингредиенты с проверкой уникальности\n",
    "    ingredients_data = []\n",
    "    ingredient_id_map = {}  # Для связи оригинального названия с ID\n",
    "    \n",
    "    for ingredient in original_data['ingredients']:\n",
    "        ingredient_name = ingredient['name']\n",
    "        lemma = ingredient_manager.get_lemma(ingredient_name)\n",
    "        \n",
    "        # Проверяем, есть ли уже такой ингредиент\n",
    "        if ingredient_manager.is_ingredient_unique(lemma):\n",
    "            # Новый уникальный ингредиент\n",
    "            ingredient_id = id_manager.get_next_ingredient_id()\n",
    "            ingredients_data.append({\n",
    "                'id': ingredient_id,\n",
    "                'name': ingredient_name,\n",
    "                'lemma': lemma\n",
    "            })\n",
    "            ingredient_id_map[ingredient_name] = ingredient_id\n",
    "            ingredient_manager.add_ingredient_lemma(lemma)\n",
    "        else:\n",
    "            # Ингредиент уже существует, находим его ID\n",
    "            # Для этого нужно прочитать существующие данные\n",
    "            existing_id = find_ingredient_id_by_lemma(lemma, f'{output_dir}ingredients.tsv')\n",
    "            if existing_id:\n",
    "                ingredient_id_map[ingredient_name] = existing_id\n",
    "    \n",
    "    # 2. Создаем TSV для шагов\n",
    "    steps_data = []\n",
    "    for step in original_data['steps']:\n",
    "        step_id = id_manager.get_next_step_id()\n",
    "        steps_data.append({\n",
    "            'id': step_id,\n",
    "            'recipe_id': recipe_id,\n",
    "            'step_number': step['step_number'],\n",
    "            'step_index': step['step_index'],\n",
    "            'description': step['description'],\n",
    "            'image_url': step['image_url'],\n",
    "        })\n",
    "    \n",
    "    # 3. Создаем TSV для рецепта\n",
    "    video_id = id_manager.get_next_video_id()\n",
    "    \n",
    "    # Получаем ID ингредиентов для этого рецепта\n",
    "    recipe_ingredient_ids = []\n",
    "    for ingredient in original_data['ingredients']:\n",
    "        ingredient_name = ingredient['name']\n",
    "        if ingredient_name in ingredient_id_map:\n",
    "            recipe_ingredient_ids.append(str(ingredient_id_map[ingredient_name]))\n",
    "    \n",
    "    recipe_data = [{\n",
    "        'id': recipe_id,\n",
    "        'title': '*',\n",
    "        'url': original_data['url'],\n",
    "        'ingredient_ids': '|'.join(recipe_ingredient_ids),\n",
    "        'step_ids': '|'.join(str(step['id']) for step in steps_data),\n",
    "        'video_id': video_id,\n",
    "        'total_steps': original_data['total_steps'],\n",
    "        'total_ingredients': len(recipe_ingredient_ids),\n",
    "        'mp4_url': original_data['video']['mp4'][0] if original_data['video']['mp4'] else '',\n",
    "        'youtube_url': original_data['video']['youtube'][0] if original_data['video']['youtube'] else ''\n",
    "    }]\n",
    "    \n",
    "    # Сохраняем в TSV файлы\n",
    "    save_to_tsv(ingredients_data, f'{output_dir}ingredients.tsv', ['id', 'name', 'lemma'])\n",
    "    save_to_tsv(steps_data, f'{output_dir}steps_raw.tsv', ['id', 'recipe_id', 'step_number', 'step_index', 'description', 'image_url'])\n",
    "    save_to_tsv(recipe_data, f'{output_dir}recipes_raw.tsv', ['id', 'title', 'url', 'ingredient_ids', 'step_ids', 'video_id', 'total_steps', 'total_ingredients', 'mp4_url', 'youtube_url'])\n",
    "    \n",
    "def save_to_tsv(data: List[Dict], filename: str, fieldnames: List[str]):\n",
    "    \"\"\"\n",
    "    Сохраняет данные в TSV файл\n",
    "    \"\"\"\n",
    "    need_header = not os.path.exists(filename)\n",
    "    with open(filename, 'a', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames, delimiter='\\t')\n",
    "        if need_header:\n",
    "            writer.writeheader()\n",
    "        writer.writerows(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel 'tfgpu (Python 3.9.19)'. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details. ENOENT: no such file or directory, open 'C:\\Users\\user\\AppData\\Local\\Temp;E:\\ffmpeg-master-latest-win64-gpl-shared\\bin;\\kernel-v2-12488haYvoNCT31n2.json'"
     ]
    }
   ],
   "source": [
    "urls = ['https://eda.video/uzbekskaia-dymliama', 'https://eda.video/losos-v-slivocnom-souse-na-skovorode']\n",
    "base_url=\"https://eda.video\"\n",
    "if not os.path.isdir('./data'):\n",
    "    os.mkdir('./data')\n",
    "for url in urls:\n",
    "    try:\n",
    "        # Парсим шаги\n",
    "        steps = parse_recipe_steps_advanced(url, base_url)\n",
    "        if steps:\n",
    "                print(f\"Найдено шагов: {len(steps)}\")\n",
    "                \n",
    "                # Парсим ингредиенты\n",
    "                response = requests.get(url)\n",
    "                soup = BeautifulSoup(response.text, 'html.parser')\n",
    "                ingredients = parse_ingredients_advanced(soup)\n",
    "                video_url=find_video_links_advanced(soup, base_url)\n",
    "                # Создаем полную структуру рецепта\n",
    "                recipe_data = {\n",
    "                    'url': url,\n",
    "                    'ingredients': ingredients,\n",
    "                    'steps': steps,\n",
    "                    'total_steps': len(steps),\n",
    "                    'video':video_url\n",
    "                }\n",
    "                \n",
    "                json_to_tsv(recipe_data, \"./data/\")\n",
    "                print(\"Данные сохранены в папку data\")\n",
    "        else:\n",
    "                raise Exception(\"Анлуко\")\n",
    "    except Exception as e:\n",
    "        print(f\"Не удалось распарсить рецепт: {url}, потому что {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

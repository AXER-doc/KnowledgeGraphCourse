{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9349e6c1-d9dd-49e3-ab28-70df6f404a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import json\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from rdflib import Graph, URIRef, OWL, RDF, RDFS, Literal, Namespace\n",
    "from urllib.parse import unquote, quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28b5f3d-2062-4739-8826-159bf00b6248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пути к файлам\n",
    "main_data_path = 'filtered_data.json'\n",
    "friends_data_path = 'lovecraft_friends.json'  # Файл с друзьями Лавкрафта\n",
    "output_path = 'combined_data.json'\n",
    "\n",
    "# Загрузка основной базы данных\n",
    "with open(main_data_path, 'r', encoding='utf-8') as main_file:\n",
    "    main_data = json.load(main_file)\n",
    "\n",
    "# Загрузка данных о друзьях Лавкрафта\n",
    "with open(friends_data_path, 'r', encoding='utf-8') as friends_file:\n",
    "    friends_data = json.load(friends_file)\n",
    "\n",
    "# Проверка на дубликаты по ключу \"title\"\n",
    "titles_in_main_data = {entity['title'] for entity in main_data}\n",
    "unique_friends_data = [friend for friend in friends_data if friend['title'] not in titles_in_main_data]\n",
    "\n",
    "# Объединение данных\n",
    "combined_data = main_data + unique_friends_data\n",
    "\n",
    "# Сохранение объединенных данных\n",
    "with open(output_path, 'w', encoding='utf-8') as output_file:\n",
    "    json.dump(combined_data, output_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "print(f\"Данные успешно объединены и сохранены в '{output_path}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa39081-0b35-4a88-8f59-d9537eb70031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from rdflib import Graph, Namespace, RDF, RDFS, OWL, Literal, URIRef, BNode\n",
    "from urllib.parse import quote, unquote\n",
    "from rdflib.namespace import XSD\n",
    "\n",
    "# Пути к файлам\n",
    "data_path = 'combined_data.json'\n",
    "output_ttl = 'lovecraft_ontology.ttl'\n",
    "\n",
    "# Загрузка данных\n",
    "with open(data_path, 'r') as data_file:\n",
    "    cleaned_data = json.load(data_file)\n",
    "\n",
    "# Создаем RDF-граф\n",
    "g = Graph()\n",
    "EX = Namespace(\"http://example.org/lovecraft#\")\n",
    "g.bind(\"owl\", OWL)\n",
    "g.bind(\"rdfs\", RDFS)\n",
    "g.bind(\"ex\", URIRef(\"http://example.org/lovecraft#\"))\n",
    "\n",
    "property_renaming_map = {\n",
    "    \"hasAffiliation\": {\n",
    "        \"Work\": \"hasAffiliationWork\",\n",
    "        \"RealWorldPerson\": \"hasAffiliationRealWorldPerson\",\n",
    "        \"Organisation\": \"hasAffiliationOrganisation\",\n",
    "        \"Character\": \"hasAffiliationCharacter\"\n",
    "    },\n",
    "    \"hasAppearance\": {\n",
    "        \"Work\": \"hasAppearanceWork\",\n",
    "        \"Location\": \"hasAppearanceLocation\",\n",
    "        \"Artefact\": \"hasAppearanceArtefact\",\n",
    "        \"Organisation\": \"hasAppearanceOrganisation\",\n",
    "        \"Character\": \"hasAppearanceCharacter\"\n",
    "    },\n",
    "    \"wasCreatedBy\": {\n",
    "        \"Work\": \"wasCreatedByWork\",\n",
    "        \"Artefact\": \"wasCreatedByArtefact\",\n",
    "        \"Organisation\": \"wasCreatedByOrganisation\",\n",
    "        \"Character\": \"wasCreatedByCharacter\",\n",
    "        \"Location\": \"wasCreatedByLocation\"\n",
    "    },\n",
    "    \"madeFirstAppearanceOn\": {\n",
    "        \"Work\": \"madeFirstAppearanceOnWork\",\n",
    "        \"Location\": \"madeFirstAppearanceOnLocation\",\n",
    "        \"Artefact\": \"madeFirstAppearanceOnArtefact\",\n",
    "        \"Organisation\": \"madeFirstAppearanceOnOrganisation\",\n",
    "        \"Character\": \"madeFirstAppearanceOnCharacter\"\n",
    "    },\n",
    "    \"hasAlternativeName\": {\n",
    "        \"RealWorldPerson\": \"hasAlternativeNameRealWorldPerson\",\n",
    "        \"Location\": \"hasAlternativeNameLocation\",\n",
    "        \"Artefact\": \"hasAlternativeNameArtefact\",\n",
    "        \"Organisation\": \"hasAlternativeNameOrganisation\",\n",
    "        \"Character\": \"hasAlternativeNameCharacter\"\n",
    "    },\n",
    "    \"hasType\": {\n",
    "        \"Location\": \"hasTypeLocation\",\n",
    "        \"Artefact\": \"hasTypeArtefact\",\n",
    "        \"Organisation\": \"hasTypeOrganisation\"\n",
    "    },\n",
    "    \"isLocatedAt\": {\n",
    "        \"Location\": \"isLocatedAtLocation\",\n",
    "        \"Artefact\": \"isLocatedAtArtefact\",\n",
    "        \"Organisation\": \"isLocatedAtOrganisation\",\n",
    "        \"Character\": \"isLocatedAtCharacter\"\n",
    "    },\n",
    "    \"hasOrigin\": {\n",
    "        \"Character\": \"hasOriginCharacter\",\n",
    "        \"Location\": \"hasOriginLocation\",\n",
    "        \"Artefact\": \"hasOriginArtefact\"\n",
    "    }\n",
    "}\n",
    "\n",
    "def clean_uri(uri):\n",
    "    \"\"\"Удаляет кавычки, пробелы и декодирует URI.\"\"\"\n",
    "    return unquote(uri).replace('%22', '').replace('\"', '').replace(\"'\", '').strip().replace(\" \", \"_\")\n",
    "    \n",
    "def rename_property(prop_name, domain, renaming_map):\n",
    "    if prop_name in renaming_map and domain in renaming_map[prop_name]:\n",
    "        return renaming_map[prop_name][domain]\n",
    "    return prop_name\n",
    "    \n",
    "# Словари для каждого класса\n",
    "Work_property_map = {\n",
    "    \"affiliations\": {\"name\": \"hasAffiliation\", \"type\": [], \"domain\": \"Work\", \"range\": [\"Organisation\", \"Character\", \"Work\"]},\n",
    "    \"appearances\": {\"name\": \"hasAppearance\", \"type\": [], \"domain\": \"Work\", \"range\": [\"Character\", \"Artefact\", \"Location\"]},\n",
    "    \"appears_in\": {\"name\": \"isPartOfSeries\", \"type\": [\"transitive\"], \"inverse\": \"hasSeriesPart\", \"domain\": \"Work\", \"range\": \"Work\"},\n",
    "    \"author\": {\"name\": \"hasAuthor\", \"type\": [], \"inverse\": \"isAuthorOf\", \"domain\": \"Work\", \"range\": \"RealWorldPerson\"},\n",
    "    \"based_on\": {\"name\": \"isBasedOn\", \"type\": [], \"domain\": \"Work\", \"range\": \"Work\"},\n",
    "    \"country\": {\"name\": \"hasCountryOfOrigin\", \"type\": [\"functional\"], \"domain\": \"Work\", \"range\": \"Location\"},\n",
    "    \"date_of_writing\": {\"name\": \"wasWrittenOn\", \"type\": [\"functional\"], \"domain\": \"Work\", \"range\": \"xsd:string\"},\n",
    "    \"genre(s)\": {\"name\": \"hasGenre\", \"type\": [], \"domain\": \"Work\", \"range\": \"xsd:string\"},\n",
    "    \"language\": {\"name\": \"isInLanguage\", \"type\": [\"functional\"], \"domain\": \"Work\", \"range\": \"xsd:string\"},\n",
    "    \"pages\": {\"name\": \"hasPageCount\", \"type\": [\"functional\"], \"domain\": \"Work\", \"range\": \"xsd:string\"},\n",
    "    \"publication\": {\"name\": \"isPublishedAs\", \"type\": [], \"domain\": \"Work\", \"range\": \"xsd:string\"},\n",
    "    \"publication_date\": {\"name\": \"wasPublishedOn\", \"type\": [\"functional\"], \"domain\": \"Work\", \"range\": \"xsd:string\"},\n",
    "    \"release_date\": {\"name\": \"wasReleasedOn\", \"type\": [\"functional\"], \"domain\": \"Work\", \"range\": \"xsd:string\"},\n",
    "    \"series\": {\"name\": \"isPartOfSeries\", \"type\": [\"transitive\"], \"domain\": \"Work\", \"range\": \"Work\"},\n",
    "    \"writer\": {\"name\": \"hasWriter\", \"type\": [\"functional\"], \"domain\": \"Work\", \"range\": \"RealWorldPerson\"},\n",
    "}\n",
    "\n",
    "\n",
    "RealWorldPerson_property_map = {\n",
    "    \"affiliations\": {\"name\": \"hasAffiliation\", \"type\": [], \"domain\": \"RealWorldPerson\", \"range\": [\"Organisation\", \"Work\"]},\n",
    "    \"also_known_as\": {\"name\": \"hasAlternativeName\", \"type\": [\"functional\"], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"birth_date\": {\"name\": \"wasBornOn\", \"type\": [\"functional\"], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"birthplace\": {\"name\": \"hasBirthplace\", \"type\": [\"functional\"], \"domain\": \"RealWorldPerson\", \"range\": [\"Location\"]},\n",
    "    \"connection_to_the_mythos\": {\"name\": \"isConnectedToMythos\", \"type\": [], \"domain\": \"RealWorldPerson\", \"range\": \"Work\"},\n",
    "    \"death_date\": {\"name\": \"diedOn\", \"type\": [\"functional\"], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"full_name\": {\"name\": \"hasFullName\", \"type\": [\"functional\"], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"mate\": {\"name\": \"hasRealPersonMate\", \"type\": [\"symmetric\"], \"inverse\": \"isRealPersonMateOf\", \"domain\": \"RealWorldPerson\", \"range\": [\"RealWorldPerson\"]},\n",
    "    \"nationality\": {\"name\": \"hasNationality\", \"type\": [\"functional\"], \"domain\": \"RealWorldPerson\", \"range\": \"Location\"},\n",
    "    \"notable_works\": {\"name\": \"isKnownFor\", \"type\": [], \"domain\": \"RealWorldPerson\", \"range\": \"Work\"},\n",
    "    \"occupation\": {\"name\": \"hasOccupation\", \"type\": [], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"pseudonym(s)\": {\"name\": \"hasPseudonym\", \"type\": [], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"relatives\": {\"name\": \"hasRelativeRealPerson\", \"type\": [\"symmetric\"], \"domain\": \"RealWorldPerson\", \"range\": \"RealWorldPerson\"},\n",
    "    \"spouses\": {\"name\": \"hasSpouse\", \"type\": [\"functional\", \"symmetric\"], \"inverse\": \"isSpouseOf\", \"domain\": \"RealWorldPerson\", \"range\": [\"RealWorldPerson\"]},\n",
    "    \"website\": {\"name\": \"hasWebsite\", \"type\": [\"functional\"], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"years_active\": {\"name\": \"hasYearsActive\", \"type\": [], \"domain\": \"RealWorldPerson\", \"range\": \"xsd:string\"},\n",
    "    \"children\": {\"name\": \"hasChildren\", \"type\": [], \"domain\": \"RealWorldPerson\", \"range\": \"RealWorldPerson\"},\n",
    "}\n",
    "\n",
    "Location_property_map = {\n",
    "    \"accessibility\": {\"name\": \"hasAccessibility\", \"type\": [], \"domain\": \"Location\", \"range\": \"xsd:string\"},\n",
    "    \"also_known_as\": {\"name\": \"hasAlternativeName\", \"type\": [\"functional\"], \"domain\": \"Location\", \"range\": \"xsd:string\"},\n",
    "    \"appearances\": {\"name\": \"hasAppearance\", \"type\": [], \"domain\": \"Location\", \"range\": \"Work\"},\n",
    "    \"country\": {\"name\": \"isInCountry\", \"type\": [\"functional\"], \"domain\": \"Location\", \"range\": [\"Location\"]},\n",
    "    \"destroyed\": {\"name\": \"wasDestroyedOn\", \"type\": [\"functional\"], \"domain\": \"Location\", \"range\": \"xsd:string\"},\n",
    "    \"first_appearance\": {\"name\": \"madeFirstAppearanceOn\", \"type\": [\"functional\"], \"domain\": \"Location\", \"range\": \"Work\"},\n",
    "    \"inhabitants\": {\"name\": \"isInhabitedBy\", \"type\": [\"transitive\"], \"domain\": \"Location\", \"range\": \"Character\"},\n",
    "    \"location\": {\"name\": \"isLocatedAt\", \"type\": [\"functional\"], \"domain\": \"Location\", \"range\": [\"Location\"]},\n",
    "    \"notable_features\": {\"name\": \"hasNotableFeature\", \"type\": [], \"domain\": \"Location\", \"range\": \"xsd:string\"},\n",
    "    \"purpose\": {\"name\": \"hasPurpose\", \"type\": [], \"domain\": \"Location\", \"range\": \"xsd:string\"},\n",
    "    \"type\": {\"name\": \"hasType\", \"type\": [], \"domain\": \"Location\", \"range\": \"xsd:string\"},\n",
    "    \"origin\": {\"name\": \"hasOrigin\", \"type\": [\"functional\"], \"domain\": \"Location\", \"range\": [\"Location\"]}\n",
    "}\n",
    "\n",
    "Artefact_property_map = {\n",
    "    \"also_known_as\": {\"name\": \"hasAlternativeName\", \"type\": [\"functional\"], \"domain\": \"Artefact\", \"range\": \"xsd:string\"},\n",
    "    \"appearances\": {\"name\": \"hasAppearance\", \"type\": [], \"domain\": \"Artefact\", \"range\": \"Work\"},\n",
    "    \"created_by\": {\"name\": \"wasCreatedBy\", \"type\": [\"functional\"], \"inverse\": \"created\", \"domain\": \"Artefact\", \"range\": \"RealWorldPerson\"},\n",
    "    \"destroyed\": {\"name\": \"wasDestroyedOn\", \"type\": [\"functional\"], \"domain\": \"Artefact\", \"range\": \"xsd:string\"},\n",
    "    \"first_appearance\": {\"name\": \"madeFirstAppearanceOn\", \"type\": [\"functional\"], \"domain\": \"Artefact\", \"range\": \"Work\"},\n",
    "    \"function\": {\"name\": \"hasFunction\", \"type\": [], \"domain\": \"Artefact\", \"range\": \"xsd:string\"},\n",
    "    \"location\": {\"name\": \"isLocatedAt\", \"type\": [\"functional\"], \"domain\": \"Artefact\", \"range\": [\"Location\", \"Work\"]},\n",
    "    \"origin\": {\"name\": \"hasOrigin\", \"type\": [\"functional\"], \"domain\": \"Artefact\", \"range\": [\"Location\"]},\n",
    "    \"place_of_origin\": {\"name\": \"hasPlaceOfOrigin\", \"type\": [\"functional\"], \"domain\": \"Artefact\", \"range\": [\"Location\", \"xsd:string\"]},\n",
    "    \"type\": {\"name\": \"hasType\", \"type\": [], \"domain\": \"Artefact\", \"range\": \"xsd:string\"},\n",
    "    \"used_by\": {\"name\": \"isUsedBy\", \"type\": [\"transitive\"], \"domain\": \"Artefact\", \"range\": [\"Character\"]}\n",
    "}\n",
    "\n",
    "Organisation_property_map = {\n",
    "    \"affiliations\": {\"name\": \"hasAffiliation\", \"type\": [], \"domain\": \"Organisation\", \"range\": [\"Organisation\", \"Character\", \"Work\"]},\n",
    "    \"also_known_as\": {\"name\": \"hasAlternativeName\", \"type\": [\"functional\"], \"domain\": \"Organisation\", \"range\": \"xsd:string\"},\n",
    "    \"created_by\": {\"name\": \"wasCreatedBy\", \"type\": [\"functional\"], \"inverse\": \"created\", \"domain\": \"Organisation\", \"range\": \"RealWorldPerson\"},\n",
    "    \"location\": {\"name\": \"isLocatedAt\", \"type\": [\"functional\"], \"domain\": \"Organisation\", \"range\": [\"Location\"]},\n",
    "    \"notable_members\": {\"name\": \"hasNotableMember\", \"type\": [], \"domain\": \"Organisation\", \"range\": \"RealWorldPerson\"},\n",
    "    \"purpose\": {\"name\": \"hasPurpose\", \"type\": [], \"domain\": \"Organisation\", \"range\": \"xsd:string\"},\n",
    "    \"type\": {\"name\": \"hasType\", \"type\": [], \"domain\": \"Organisation\", \"range\": \"xsd:string\"}\n",
    "}\n",
    "\n",
    "Character_property_map = {\n",
    "    \"affiliations\": {\"name\": \"hasAffiliation\", \"type\": [], \"domain\": \"Character\", \"range\": [\"Organisation\", \"Character\", \"Work\"]},\n",
    "    \"also_known_as\": {\"name\": \"hasAlternativeName\", \"type\": [\"functional\"], \"domain\": \"Character\", \"range\": \"xsd:string\"},\n",
    "    \"appearances\": {\"name\": \"hasAppearance\", \"type\": [], \"domain\": \"Character\", \"range\": \"Work\"},\n",
    "    \"created_by\": {\"name\": \"wasCreatedBy\", \"type\": [\"functional\"], \"inverse\": \"created\", \"domain\": \"Character\", \"range\": \"RealWorldPerson\"},\n",
    "    \"current_location\": {\"name\": \"isLocatedAt\", \"type\": [\"functional\"], \"domain\": \"Character\", \"range\": [\"Location\", \"xsd:string\"]},\n",
    "    \"died\": {\"name\": \"ceasedOn\", \"type\": [\"functional\"], \"domain\": \"Character\", \"range\": \"xsd:string\"},\n",
    "    \"distinctions\": {\"name\": \"hasDistinction\", \"type\": [], \"domain\": \"Character\", \"range\": \"xsd:string\"},\n",
    "    \"first_appearance\": {\"name\": \"madeFirstAppearanceOn\", \"type\": [\"functional\"], \"domain\": \"Character\", \"range\": \"Work\"},\n",
    "    \"language\": {\"name\": \"usesLanguage\", \"type\": [\"functional\"], \"domain\": \"Character\", \"range\": \"xsd:string\"},\n",
    "    \"mate\": {\"name\": \"hasCharacterMate\", \"type\": [\"functional\", \"symmetric\"], \"inverse\": \"isCharacterMateOf\", \"domain\": \"Character\", \"range\": [\"Character\"],\n",
    "    \"occupation\": {\"name\": \"hasOccupation\", \"type\": [], \"domain\": \"Character\", \"range\": \"xsd:string\"},\n",
    "    \"offspring\": {\"name\": \"hasOffspring\", \"type\": [\"transitive\"], \"inverse\": \"isOffspringOf\", \"domain\": \"Character\", \"range\": \"Character\"},\n",
    "    \"origin\": {\"name\": \"hasOrigin\", \"type\": [\"functional\"], \"domain\": \"Character\", \"range\": [\"Location\"]},\n",
    "    \"powers_and_abilities\": {\"name\": \"hasPowersAndAbilities\", \"type\": [], \"domain\": \"Character\", \"range\": \"xsd:string\"},\n",
    "    \"relatives\": {\"name\": \"hasRelativesCharacter\", \"type\": [\"symmetric\"], \"domain\": \"Character\", \"range\": \"Character\"},\n",
    "    \"species\": {\"name\": \"isOfSpecies\", \"type\": [\"functional\"], \"inverse\": \"hasIndividual\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasParent\": {\"name\": \"hasParent\", \"type\": [\"transitive\"], \"inverse\": \"hasChild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGrandParent\": {\"name\": \"hasGrandParent\", \"type\": [\"transitive\"], \"inverse\": \"hasGrandchild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGreatGrandParent\": {\"name\": \"hasGreatGrandParent\", \"type\": [\"transitive\"], \"inverse\": \"hasGreatGrandchild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasFather\": {\"name\": \"hasFather\", \"type\": [], \"inverse\": \"hasChild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasMother\": {\"name\": \"hasMother\", \"type\": [], \"inverse\": \"hasChild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasSister\": {\"name\": \"hasSister\", \"type\": [\"symmetric\"], \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasBrother\": {\"name\": \"hasBrother\", \"type\": [\"symmetric\"], \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasHalfSister\": {\"name\": \"hasHalfSister\", \"type\": [], \"inverse\": \"hasHalfSibling\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasHalfBrother\": {\"name\": \"hasHalfBrother\", \"type\": [], \"inverse\": \"hasHalfSibling\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasSon\": {\"name\": \"hasSon\", \"type\": [], \"inverse\": \"hasParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasDaughter\": {\"name\": \"hasDaughter\", \"type\": [], \"inverse\": \"hasParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasAncestor\": {\"name\": \"hasAncestor\", \"type\": [\"transitive\"], \"inverse\": \"hasDescendant\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasUncle\": {\"name\": \"hasUncle\", \"type\": [], \"inverse\": \"hasNephewOrNiece\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasCousin\": {\"name\": \"hasCousin\", \"type\": [\"symmetric\"], \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasNephew\": {\"name\": \"hasNephew\", \"type\": [], \"inverse\": \"hasUncleOrAunt\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGrandfather\": {\"name\": \"hasGrandfather\", \"type\": [], \"inverse\": \"hasGrandchild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGrandmother\": {\"name\": \"hasGrandmother\", \"type\": [], \"inverse\": \"hasGrandchild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGrandson\": {\"name\": \"hasGrandson\", \"type\": [], \"inverse\": \"hasGrandParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGranddaughter\": {\"name\": \"hasGranddaughter\", \"type\": [], \"inverse\": \"hasGrandParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGreatGrandson\": {\"name\": \"hasGreatGrandson\", \"type\": [], \"inverse\": \"hasGreatGrandParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGreatGreatGrandson\": {\"name\": \"hasGreatGreatGrandson\", \"type\": [], \"inverse\": \"hasGreatGreatGrandParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGreatGreatFather\": {\"name\": \"hasGreatGreatFather\", \"type\": [], \"inverse\": \"hasGreatGreatGrandchild\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGreatGranddaughter\": {\"name\": \"hasGreatGranddaughter\", \"type\": [], \"inverse\": \"hasGreatGrandParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGreatGrandchildren\": {\"name\": \"hasGreatGrandchildren\", \"type\": [], \"inverse\": \"hasGreatGrandParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasGreatGreatGranddaughter\": {\"name\": \"hasGreatGreatGranddaughter\", \"type\": [], \"inverse\": \"hasGreatGreatGrandParent\", \"domain\": \"Character\", \"range\": [\"Character\"]},\n",
    "    \"hasRelative\": {\"name\": \"hasRelativeCharacter\", \"type\": [\"symmetric\"], \"domain\": \"Character\", \"range\": [\"Character\"]}\n",
    "}\n",
    "}\n",
    "\n",
    "# Словарь, где ключ — название главного класса,\n",
    "# а значение — список его подклассов.\n",
    "subclass_map = {\n",
    "    \"Character\": [\n",
    "        \"Avatars\",\n",
    "        \"Chaosium\",\n",
    "        \"CharactersIncorporatedFromFolkloreMythAndReligion\",\n",
    "        \"Cults\",\n",
    "        \"DeceasedInMythos\",\n",
    "        \"Disambiguations\",\n",
    "        \"Dreamers\",\n",
    "        \"Dunwich\",\n",
    "        \"EarthNativeSpecies\",\n",
    "        \"ElderGods\",\n",
    "        \"ExtinctSpecies\",\n",
    "        \"ExtraDimensionalCharacters\",\n",
    "        \"ExtraDimensionalSpecies\",\n",
    "        \"ExtraterrestrialCharacters\",\n",
    "        \"ExtraterrestrialSpecies\",\n",
    "        \"Fictional\",\n",
    "        \"GamesAndAdaptations\",\n",
    "        \"GreatOldOnes\",\n",
    "        \"Humans\",\n",
    "        \"LifeformsAndEntities\",\n",
    "        \"MagicUsers\",\n",
    "        \"MythosCharacters\",\n",
    "        \"MythosLiterature\",\n",
    "        \"NonSapientSpecies\",\n",
    "        \"OtherSupernaturalBeings\",\n",
    "        \"OuterGods\",\n",
    "        \"RobertEHowardWorks\",\n",
    "        \"SapientSpecies\",\n",
    "        \"ServitorRaces\",\n",
    "        \"Species\",\n",
    "        \"SpeciesIncorporatedFromFolkloreMythAndReligion\"\n",
    "    ],\n",
    "    \"Work\": [\n",
    "        \"AmateurPress\",\n",
    "        \"AndersFagerWorks\",\n",
    "        \"ArkhamHorror\",\n",
    "        \"ArkhamHorrorFiction\",\n",
    "        \"Audio\",\n",
    "        \"AugustDerlethWorks\",\n",
    "        \"AveroigneCycle\",\n",
    "        \"BhyhlunSeries\",\n",
    "        \"Books\",\n",
    "        \"BrianLumleyWorks\",\n",
    "        \"Chaosium\",\n",
    "        \"ClarkAshtonSmithWorks\",\n",
    "        \"ComicBooks\",\n",
    "        \"Crossovers\",\n",
    "        \"CrossroadPress\",\n",
    "        \"Dunwich\",\n",
    "        \"Ebooks\",\n",
    "        \"ExpandedMythosAudioAdaptations\",\n",
    "        \"ExpandedMythosComicBookAdaptations\",\n",
    "        \"ExpandedMythosFilmAndTelevision\",\n",
    "        \"ExpandedMythosFilmAndTelevisionAdaptations\",\n",
    "        \"Ezines\",\n",
    "        \"Fanzines\",\n",
    "        \"FritzLeiberWorks\",\n",
    "        \"GamesAndAdaptations\",\n",
    "        \"GamingSupplements\",\n",
    "        \"HyperboreanCycle\",\n",
    "        \"JamesAllisonCycle\",\n",
    "        \"JohnDHaefele\",\n",
    "        \"LovecraftCircleAdaptations\",\n",
    "        \"LovecraftCircleAudioAdaptations\",\n",
    "        \"LovecraftCircleComicBookAdaptations\",\n",
    "        \"LovecraftCircleFilmAndTelevisionAdaptations\",\n",
    "        \"MythosAdjacentFilmAndTelevision\",\n",
    "        \"MythosAdjacentWorks\",\n",
    "        \"MythosInspiredFilmAndTelevisionWorks\",\n",
    "        \"MythosInspiredWorks\",\n",
    "        \"MythosLiterature\",\n",
    "        \"NonFictionWorks\",\n",
    "        \"OtherAuthors\",\n",
    "        \"Pastiches\",\n",
    "        \"PatHarriganWorks\",\n",
    "        \"PennyFrierson\",\n",
    "        \"Periodicals\",\n",
    "        \"PulpMagazines\",\n",
    "        \"RamseyCampbellWorks\",\n",
    "        \"RuthannaEmrysWorks\",\n",
    "        \"SpectraFiles\",\n",
    "        \"StoryCycles\",\n",
    "        \"Storybooks\",\n",
    "        \"TheSalemHawleySeries\",\n",
    "        \"Works\",\n",
    "        \"ZothiqueStoryCycle\",\n",
    "        \"HPLovecraftWorks\",\n",
    "        \"CaitlinRKiernanWorks\",\n",
    "        \"MediaAdaptations\"\n",
    "        \n",
    "    ],\n",
    "    \"RealWorldPerson\": [\n",
    "        \"AlterEgosCharactersIncorporatedFromTheRealWorld\",\n",
    "        \"AmateurPress\",\n",
    "        \"Artists\",\n",
    "        \"Audio\",\n",
    "        \"Chaosium\",\n",
    "        \"ComicBooks\",\n",
    "        \"ContentCreators\",\n",
    "        \"Critics\",\n",
    "        \"CrossroadPress\",\n",
    "        \"DeceasedRealWorld\",\n",
    "        \"DefunctRealWorld\",\n",
    "        \"Editors\",\n",
    "        \"ExpandedMythosAuthors\",\n",
    "        \"GamesAndAdaptations\",\n",
    "        \"GamingSupplements\",\n",
    "        \"KalemClub\",\n",
    "        \"LovecraftCircleAuthors\",\n",
    "        \"LovecraftsCoAuthors\",\n",
    "        \"LovecraftsCorrespondents\",\n",
    "        \"LovecraftsInspirationsAuthors\",\n",
    "        \"MythosAdjacentAuthors\",\n",
    "        \"MythosAdjacentWorks\",\n",
    "        \"MythosInspiredAuthors\",\n",
    "        \"MythosInspiredWorks\",\n",
    "        \"MythosLiterature\",\n",
    "        \"NonFictionAuthors\",\n",
    "        \"Publishers\",\n",
    "        \"RealWorld\",\n",
    "        \"RealWorldPeople\",\n",
    "        \"Scholars\",\n",
    "        \"SmallPress\",\n",
    "        \"LovecraftSFriendsAndAcquaintances\"\n",
    "    ],\n",
    "    \"Location\": [\n",
    "        \"CallOfCthulhuRealWorld\",\n",
    "        \"Dimensions\",\n",
    "        \"Dunwich\",\n",
    "        \"Ebooks\",\n",
    "        \"ExtraDimensionalLocations\",\n",
    "        \"Locations\",\n",
    "        \"LocationsIncorporatedFromFolkloreMythAndReligion\",\n",
    "        \"LocationsIncorporatedFromTheRealWorld\",\n",
    "        \"LocationsOriginatingFromMythosAdjacentWorks\",\n",
    "        \"LocationsOriginatingFromMythosInspiredWorks\",\n",
    "        \"LovecraftsInspirationsWorks\",\n",
    "        \"MythosLiterature\",\n",
    "        \"Planets\",\n",
    "        \"RealWorld\",\n",
    "        \"RegionsTerritories\",\n",
    "        \"Stars\",\n",
    "        \"Structures\"\n",
    "    ],\n",
    "    \"Artefact\": [\n",
    "        \"ArtefactsOriginatingFromMythosAdjacentWorks\",\n",
    "        \"ArtefactsOriginatingFromMythosInspiredWorks\",\n",
    "        \"LocationsOriginatingFromMythosInspiredWorks\",\n",
    "        \"LovecraftsInspirationsWorks\",\n",
    "        \"MysticalArtefacts\",\n",
    "        \"MythosBooksFictional\",\n",
    "        \"MythosLiterature\",\n",
    "        \"RegionsTerritories\",\n",
    "        \"TechnologicalArtefacts\"\n",
    "    ],\n",
    "    \"Organisation\": [\n",
    "        \"Cults\",\n",
    "        \"DefunctOrganisationsFictional\",\n",
    "        \"Events\",\n",
    "        \"MythosLiterature\",\n",
    "        \"Organisations\",\n",
    "        \"OrganisationsOriginatingFromMythosAdjacentWorks\",\n",
    "        \"OrganisationsOriginatingFromMythosInspiredWorks\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Добавляем свойства из property_map в зависимости от класса\n",
    "property_maps = {\n",
    "    \"Work\": Work_property_map,\n",
    "    \"Character\": Character_property_map,\n",
    "    \"RealWorldPerson\": RealWorldPerson_property_map,\n",
    "    \"Location\": Location_property_map,\n",
    "    \"Artefact\": Artefact_property_map,\n",
    "    \"Organisation\": Organisation_property_map\n",
    "}\n",
    "\n",
    "# Определение классов\n",
    "classes = {\n",
    "    'Work': 'Creative works such as literary pieces, articles, games, comics, and other media.',\n",
    "    'Character': 'A being from mythology or fictional lore, including deities, monsters, and heroes.',\n",
    "    'RealWorldPerson': 'A real historical or contemporary person with connections to the mythos or works.',\n",
    "    'Location': 'A place or setting, real or fictional, associated with events or entities from the mythos.',\n",
    "    'Artefact': 'An object of historical, mystical, or fictional significance, often tied to the mythos.',\n",
    "    'Organisation': 'A group or institution, real or fictional, playing a role in the mythos or related works.'\n",
    "}\n",
    "\n",
    "\n",
    "# Добавляем 6 главных классов\n",
    "for class_name, label in classes.items():\n",
    "    class_uri = URIRef(EX[clean_uri(class_name)])\n",
    "    g.add((class_uri, RDF.type, OWL.Class))\n",
    "    g.add((class_uri, RDFS.label, Literal(label, lang='en')))\n",
    "\n",
    "\n",
    "def add_subclass_hierarchy(graph, subclass_map):\n",
    "    \"\"\"\n",
    "    Для каждого главного класса (например, 'Character')\n",
    "    создаёт подклассы (Avatars, Chaosium ...) и связывает их\n",
    "    rdfs:subClassOf -> EX[Character].\n",
    "    \"\"\"\n",
    "    for main_class, sub_list in subclass_map.items():\n",
    "        main_class_uri = EX[clean_uri(main_class)]\n",
    "        \n",
    "        for sub_name in sub_list:\n",
    "            sub_uri = EX[clean_uri(sub_name)]\n",
    "            # Если вдруг не объявлено как класс — объявим\n",
    "            graph.add((sub_uri, RDF.type, OWL.Class))\n",
    "            # sub_name является подклассом main_class\n",
    "            graph.add((sub_uri, RDFS.subClassOf, main_class_uri))\n",
    "# После этого:\n",
    "add_subclass_hierarchy(g, subclass_map)\n",
    "    \n",
    "# Функция для экранирования значений для XML\n",
    "def escape_xml(value):\n",
    "    if not isinstance(value, str):\n",
    "        return value\n",
    "    return (\n",
    "        value.replace(\"&\", \"&amp;\")\n",
    "             .replace(\"<\", \"&lt;\")\n",
    "             .replace(\">\", \"&gt;\")\n",
    "             .replace(\"\\\"\", \"&quot;\")\n",
    "             .replace(\"'\", \"&apos;\")\n",
    "    ).strip()\n",
    "\n",
    "def add_subclasses_from_json(graph, default_parent_class, subclasses):\n",
    "    parent_uri = URIRef(EX[clean_uri(default_parent_class)])\n",
    "    \n",
    "    for subclass in subclasses:\n",
    "        subclass_uri = URIRef(EX[clean_uri(subclass)])\n",
    "        \n",
    "        # Проверка на самоссылку\n",
    "        if parent_uri == subclass_uri:\n",
    "            print(f\"Warning: Detected self-referential subclass: {subclass}. Skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Проверка существования класса в графе\n",
    "        if (subclass_uri, RDF.type, OWL.Class) not in graph:\n",
    "            graph.add((subclass_uri, RDF.type, OWL.Class))\n",
    "        \n",
    "        # Добавление отношения подкласса\n",
    "        graph.add((subclass_uri, RDFS.subClassOf, parent_uri))\n",
    "\n",
    "def clean_property_name(prop_name):\n",
    "    \"\"\"Удаляет лишние символы и приводит название свойства к корректному виду.\"\"\"\n",
    "    replacements = {\n",
    "        \"%28\": \"\",\n",
    "        \"%29\": \"\",\n",
    "        \"(s)\": \"s\",\n",
    "        \"(\": \"\",\n",
    "        \")\": \"\"\n",
    "    }\n",
    "    for old, new in replacements.items():\n",
    "        prop_name = prop_name.replace(old, new)\n",
    "    return prop_name\n",
    "\n",
    "\n",
    "# Создаём маппинг title -> URI\n",
    "title_to_uri_map = {clean_uri(e['title']): URIRef(EX[clean_uri(e['title'].replace(' ', '_'))]) for e in cleaned_data}\n",
    "\n",
    "# Функция для очистки инфобокса\n",
    "def clean_infobox(entity):\n",
    "    if 'infobox' in entity and isinstance(entity['infobox'], dict):\n",
    "        for key, values in entity['infobox'].items():\n",
    "            if isinstance(values, list):\n",
    "                entity['infobox'][key] = [v for v in values if clean_uri(v) != clean_uri(entity.get('title', ''))]\n",
    "            elif isinstance(values, str):\n",
    "                if clean_uri(values) == clean_uri(entity.get('title', '')):\n",
    "                    entity['infobox'][key] = None\n",
    "    return entity\n",
    "\n",
    "\n",
    "def add_object_properties(graph, property_maps):\n",
    "    for class_name, properties in property_maps.items():\n",
    "        for prop_key, prop_details in properties.items():\n",
    "            original_name = prop_details[\"name\"]\n",
    "            prop_name = clean_property_name(original_name)\n",
    "            renamed_prop = rename_property(prop_name, class_name, property_renaming_map)\n",
    "\n",
    "            prop_uri = URIRef(EX[renamed_prop])\n",
    "            domain = prop_details.get(\"domain\")\n",
    "            range_ = prop_details.get(\"range\", [])\n",
    "            prop_types = prop_details.get(\"type\", [])\n",
    "            inverse = prop_details.get(\"inverse\", None)\n",
    "\n",
    "            # Если чего-то не хватает, пропускаем\n",
    "            if not renamed_prop or not domain or not range_:\n",
    "                continue\n",
    "\n",
    "            # Приводим range_ к списку (если это одна строка)\n",
    "            if isinstance(range_, str):\n",
    "                range_ = [range_.strip()]\n",
    "\n",
    "            # Добавляем, что domain - это класс\n",
    "            domain_uri = URIRef(EX[domain])\n",
    "            graph.add((domain_uri, RDF.type, OWL.Class))\n",
    "\n",
    "            #\n",
    "            # --- ВАЖНОЕ: Определяем тип свойства (ObjectProperty vs DatatypeProperty)\n",
    "            #\n",
    "            # Проверяем, все ли элементы range_ начинаются с \"xsd:\"\n",
    "            # Если да — объявим DatatypeProperty, иначе — ObjectProperty\n",
    "            #\n",
    "            for r in range_:\n",
    "                range_uri = URIRef(EX[r]) if not r.startswith(\"xsd:\") else getattr(XSD, r.split(\":\")[1], None)\n",
    "                if range_uri:\n",
    "                    graph.add((range_uri, RDF.type, OWL.Class if not r.startswith(\"xsd:\") else RDFS.Datatype))\n",
    "\n",
    "            graph.add((prop_uri, RDF.type, OWL.ObjectProperty))\n",
    "            graph.add((prop_uri, RDFS.label, Literal(renamed_prop)))\n",
    "            graph.add((prop_uri, RDFS.domain, domain_uri))\n",
    "\n",
    "            #\n",
    "            # --- Обработка range ---\n",
    "            #\n",
    "            if len(range_) > 1:\n",
    "                # Если несколько range, собираем их в union\n",
    "                union_bnode = BNode()\n",
    "                graph.add((union_bnode, RDF.type, OWL.Class))\n",
    "                current = union_bnode\n",
    "                for r in range_[:-1]:\n",
    "                    next_node = BNode()\n",
    "                    graph.add((current, RDF.first, URIRef(EX[r]) if not r.startswith(\"xsd:\") else getattr(XSD, r.split(\":\")[1], None)))\n",
    "                    graph.add((current, RDF.rest, next_node))\n",
    "                    current = next_node\n",
    "                last_range = range_[-1]\n",
    "                graph.add((current, RDF.first, URIRef(EX[last_range]) if not last_range.startswith(\"xsd:\") else getattr(XSD, last_range.split(\":\")[1], None)))\n",
    "                graph.add((current, RDF.rest, RDF.nil))\n",
    "\n",
    "                graph.add((prop_uri, RDFS.range, union_bnode))\n",
    "            else:\n",
    "                # Один range\n",
    "                r = range_[0]\n",
    "                range_uri = URIRef(EX[r]) if not r.startswith(\"xsd:\") else getattr(XSD, r.split(\":\")[1], None)\n",
    "                graph.add((prop_uri, RDFS.range, range_uri))\n",
    "\n",
    "            #\n",
    "            # --- Проставляем типы свойств (functional, symmetric, transitive...)\n",
    "            #\n",
    "            for prop_type in prop_types:\n",
    "                if prop_type == \"symmetric\":\n",
    "                    graph.add((prop_uri, RDF.type, OWL.SymmetricProperty))\n",
    "                elif prop_type == \"transitive\":\n",
    "                    graph.add((prop_uri, RDF.type, OWL.TransitiveProperty))\n",
    "                elif prop_type == \"functional\":\n",
    "                    graph.add((prop_uri, RDF.type, OWL.FunctionalProperty))\n",
    "\n",
    "            #\n",
    "            # --- Если есть inverse\n",
    "            #\n",
    "            if inverse and not range_[0].startswith(\"xsd:\"):\n",
    "                inverse_uri = URIRef(EX[clean_property_name(inverse)])\n",
    "                graph.add((inverse_uri, RDF.type, OWL.ObjectProperty))\n",
    "                graph.add((inverse_uri, RDFS.label, Literal(inverse)))\n",
    "                graph.add((inverse_uri, RDFS.domain, URIRef(EX[range_[0]])))\n",
    "                graph.add((inverse_uri, RDFS.range, domain_uri))\n",
    "                graph.add((prop_uri, OWL.inverseOf, inverse_uri))\n",
    "                graph.add((inverse_uri, OWL.inverseOf, prop_uri))\n",
    "\n",
    "add_object_properties(g, property_maps)\n",
    "\n",
    "\n",
    "\n",
    "def add_individuals(entity):\n",
    "    \"\"\"\n",
    "    Добавляем индивида (entity) в граф:\n",
    "      - entity['class'] => базовый класс (напр. Character)\n",
    "      - создаём триплет :Entity rdf:type :Class :Subclass\n",
    "      - добавляем label, аннотации, и заполняем свойства из инфобокса\n",
    "    \"\"\"\n",
    "    if not entity.get(\"title\") or not entity.get(\"class\"):\n",
    "        return\n",
    "\n",
    "    # Чистим URI\n",
    "    title = clean_uri(entity['title'].replace(' ', '_'))\n",
    "    parent_class_name = clean_uri(entity['class'].replace(' ', '_'))\n",
    "\n",
    "    # URI для индивида, родительского класса и подкласса\n",
    "    entity_uri = title_to_uri_map.get(title, URIRef(EX[title]))\n",
    "    parent_class_uri = URIRef(EX[parent_class_name])\n",
    "\n",
    "    # 1) Привязка к базовому классу\n",
    "    g.add((entity_uri, RDF.type, parent_class_uri))\n",
    "    g.add((entity_uri, RDFS.label, Literal(escape_xml(entity['title']))))\n",
    "\n",
    "    # 2) Привязка к подклассу (если указан)\n",
    "    if 'subclass' in entity:\n",
    "        subclasses = entity['subclass'] if isinstance(entity['subclass'], list) else [entity['subclass']]\n",
    "        for subclass in subclasses:\n",
    "            cleaned_subclass = clean_uri(subclass).lower().strip()\n",
    "            cleaned_title = clean_uri(entity['title']).lower().strip()\n",
    "            if cleaned_subclass == cleaned_title:\n",
    "                print(f\"Skipping self-referential subclass: {subclass}\")\n",
    "                continue\n",
    "            \n",
    "            subclass_uri = URIRef(EX[clean_uri(subclass)])\n",
    "            if (subclass_uri, RDF.type, OWL.Class) not in g:\n",
    "                g.add((subclass_uri, RDF.type, OWL.Class))\n",
    "            \n",
    "            g.add((entity_uri, RDF.type, subclass_uri))\n",
    "\n",
    "    # 3) Если есть поле content — добавляем как аннотацию\n",
    "    if 'content' in entity:\n",
    "        g.add((entity_uri, EX['hasAnnotation'], Literal(escape_xml(entity['content']))))\n",
    "\n",
    "    # 4) Обрабатываем поля инфобокса (если есть)\n",
    "    entity = clean_infobox(entity)\n",
    "    if 'infobox' in entity and isinstance(entity['infobox'], dict):\n",
    "        class_map = property_maps.get(parent_class_name, {})\n",
    "        for key, values in entity['infobox'].items():\n",
    "            if key not in class_map:\n",
    "                print(f\"Свойство '{key}' пропущено для класса '{parent_class_name}'\")\n",
    "                continue\n",
    "            renamed_property = rename_property(key, parent_class_name, property_renaming_map)\n",
    "            prop_details = class_map.get(key, {\"name\": renamed_property, \"range\": []})\n",
    "            prop_uri = URIRef(EX[clean_uri(prop_details[\"name\"])])\n",
    "\n",
    "            if isinstance(values, list):\n",
    "                for v in values:\n",
    "                    target_uri = title_to_uri_map.get(clean_uri(v), Literal(escape_xml(v)))\n",
    "                    g.add((entity_uri, prop_uri, target_uri))\n",
    "            elif isinstance(values, str):\n",
    "                target_uri = title_to_uri_map.get(clean_uri(values), Literal(escape_xml(values)))\n",
    "                g.add((entity_uri, prop_uri, target_uri))\n",
    "\n",
    "for entity in cleaned_data:\n",
    "    add_individuals(entity)\n",
    "\n",
    "g.serialize(output_ttl, format=\"turtle\")\n",
    "print(f\"Ontology saved to '{output_ttl}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a0f9572-48d3-4ed0-8269-56890c40e468",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_uri(uri):\n",
    "    \"\"\"Удаляет или кодирует недопустимые символы в URI.\"\"\"\n",
    "    if not isinstance(uri, str):\n",
    "        return uri\n",
    "    return (quote(unquote(uri))\n",
    "            .replace('%22', '')\n",
    "            .replace('%23', '#')\n",
    "            .replace('%3A', ':')\n",
    "            .replace('%2C', ',')\n",
    "            .replace('%22', '')\n",
    "            .replace('\"', '')\n",
    "            .replace('(', '_')  # Заменяем скобки на _\n",
    "            .replace(')', '_')\n",
    "            .replace('<', '_')  # Заменяем недопустимые символы\n",
    "            .replace('>', '_')\n",
    "            .replace('|', '_')\n",
    "            .replace(' ', '_')  # Пробелы заменяем на _\n",
    "            .strip())\n",
    "\n",
    "def escape_literal(literal):\n",
    "    \"\"\"Удаляет или заменяет специальные символы в литералах.\"\"\"\n",
    "    if not isinstance(literal, str):\n",
    "        return literal\n",
    "    return (literal\n",
    "            .replace('&amp;', '&')\n",
    "            .replace('&lt;', '<')\n",
    "            .replace('&gt;', '>')\n",
    "            .replace('&quot;', '\"')\n",
    "            .replace('&apos;', \"'\")\n",
    "            .replace('🐙', '')  # Удаляем специфические символы\n",
    "            .strip())\n",
    "\n",
    "def process_ttl(input_ttl, output_ttl):\n",
    "    g = Graph()\n",
    "    g.parse(input_ttl, format=\"turtle\")\n",
    "\n",
    "    updated_graph = Graph()\n",
    "    updated_graph.bind(\"ex\", URIRef(\"http://example.org/lovecraft#\"))\n",
    "    updated_graph.bind(\"owl\", OWL)\n",
    "    updated_graph.bind(\"rdfs\", RDFS)\n",
    "\n",
    "    # Очистка URI и литералов\n",
    "    for s, p, o in g:\n",
    "        try:\n",
    "            # Обработка субъектов (s) и объектов (o)\n",
    "            if isinstance(s, URIRef):\n",
    "                s = URIRef(clean_uri(str(s)))\n",
    "            if isinstance(o, URIRef):\n",
    "                o = URIRef(clean_uri(str(o)))\n",
    "\n",
    "            # Очистка предикатов (p)\n",
    "            if isinstance(p, URIRef):\n",
    "                namespace, p_name = str(p).rsplit(\"#\", 1)\n",
    "                p = URIRef(f\"{namespace}#{clean_uri(p_name)}\")\n",
    "\n",
    "            # Замена пустых значений\n",
    "            if p in [URIRef(\"http://example.org/lovecraft#hasOccupation\"),\n",
    "                     URIRef(\"http://example.org/lovecraft#isLocatedAt\")] and o == URIRef(\"http://example.org/lovecraft#N/A\"):\n",
    "                o = OWL.Nothing\n",
    "\n",
    "            # Экранирование литералов\n",
    "            if isinstance(o, Literal):\n",
    "                o = Literal(escape_literal(str(o)))\n",
    "\n",
    "            # Добавление триплета в новый граф\n",
    "            updated_graph.add((s, p, o))\n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обработке триплета ({s}, {p}, {o}): {e}\")\n",
    "\n",
    "    # Сохранение обновленного графа\n",
    "    updated_graph.serialize(output_ttl, format=\"turtle\")\n",
    "    print(f\"Processed TTL saved to {output_ttl}\")\n",
    "\n",
    "# Пример вызова функции\n",
    "process_ttl(\"lovecraft_ontology.ttl\", \"processed_lovecraft_ontology.ttl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6f29fc-2ed3-4026-9d2a-837c22de65ac",
   "metadata": {},
   "source": [
    "## Следующую часть кода можно избежать, поднастроив немного парсинг. В данном случае, идет объединение всех значений в указанных полях в одну строку, чтобы не было конфликта в Протеже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f04e90-b2cc-4e8f-8262-a15ade98617c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_and_merge_ttl(input_file, output_file):\n",
    "    try:\n",
    "        g = Graph()\n",
    "        g.parse(input_file, format='turtle')  # Чтение TTL\n",
    "\n",
    "        # Пространство имен\n",
    "        EX = Namespace(\"http://example.org/lovecraft#\")\n",
    "        \n",
    "        # Список полей для объединения\n",
    "        fields_to_merge = [\n",
    "            \"wasCreatedOn\", \"wasCreatedBy\", \"wasWrittenOn\", \"isInLanguage\",\n",
    "            \"hasPageCount\", \"wasPublishedOn\", \"wasReleasedOn\", \"hasWriter\",\n",
    "            \"madeFirstAppearanceOn\", \"hasAlternativeName\", \"wasBornOn\",\n",
    "            \"hasBirthplace\", \"diedOn\", \"hasFullName\", \"hasNationality\",\n",
    "            \"hasWebsite\", \"isInCountry\", \"wasDestroyedOn\", \"isLocatedAt\",\n",
    "            \"hasOrigin\", \"hasPlaceOfOrigin\", \"ceasedOn\", \"usesLanguage\", \"\"\n",
    "]\n",
    "        # Словарь для хранения объединённых значений\n",
    "        merged_data = {}\n",
    "\n",
    "        # Объединяем данные по указанным полям\n",
    "        for field in fields_to_merge:\n",
    "            for subject, obj in g.subject_objects(EX[field]):\n",
    "                key = (subject, EX[field])\n",
    "                if key not in merged_data:\n",
    "                    merged_data[key] = []\n",
    "                merged_data[key].append(str(obj))\n",
    "\n",
    "        # Удаляем старые данные из графа и добавляем объединённые\n",
    "        for (subject, predicate), values in merged_data.items():\n",
    "            g.remove((subject, predicate, None))\n",
    "            merged_value = \" / \".join(values)\n",
    "            g.add((subject, predicate, Literal(merged_value)))\n",
    "\n",
    "        # Сохраняем обновлённый граф в формате TTL\n",
    "        g.serialize(destination=output_file, format='turtle')\n",
    "        print(f\"Merged TTL saved to '{output_file}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка: {e}\")\n",
    "\n",
    "# Запуск\n",
    "validate_and_merge_ttl('processed_lovecraft_ontology.ttl', 'processed_lovecraft_ontology_merged.ttl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
